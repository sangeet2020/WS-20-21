{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we will train an ngram instance to compute the probability distribution of `n-1` words and further use this distribution to generate texts.\n",
    "\n",
    "To proceed we tokenize the given corpora using `nltk.word_tokenize` and use the given class of `BasicNgram` to train an ngram model from the earlier obtained tokens. Once the ngram model is trained we start with the first token i.e. we pass this token as the first context of the ngram and generate a random token using `generate()` method. Once we have the randomly generated token, it is appended to the first token and again passed altogether to generate another random token and the process goes on. We can see here that `generate()` is actually exploiting the probability distribution to generate the next random token given the last `n-1` token. \n",
    "\n",
    "All the randomly generated tokens are stored and further de-tokenized using `TreebankWordDetokenizer`. Another alternative could have been that we store the tokens in a string and join them to produce a sentence (the alternative script has been commented in the function `post_process()`). However, `TreebankWordDetokenizer` takes care of white space gaps between token and punctuation. Hence, I used this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# author : Sangeet Sagar\n",
    "# e-mail : sasa00001@stud.uni-saarland.de\n",
    "# Organization: Universit√§t des Saarlandes\n",
    "\n",
    "\"\"\"\n",
    "Given a text file, train a ngram instance to compute probablity disribution\n",
    "and generate a random sentence.\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "from ngram import *\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "\n",
    "def data_prep(filename):\n",
    "    \"\"\"Perform pre-processing steps in the input file and tokenize it.\n",
    "\n",
    "    Args:\n",
    "        filename (str): path to file\n",
    "\n",
    "    Returns:\n",
    "        list:tokens- list containing tokenized words of the input text file \n",
    "\n",
    "    \"\"\"\n",
    "    file_content = open(filename, 'r', encoding='utf-8-sig').read()\n",
    "    file_content = file_content.lower()\n",
    "    tokens = nltk.word_tokenize(file_content)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def text_generate(tokens, n, length, estimator):\n",
    "    \"\"\"Train an ngram model to compute probablity disribution and generate a \n",
    "    sequence of random words.\n",
    "\n",
    "    Args:\n",
    "        tokens (str): list of tokens\n",
    "        n (str): number of previous tokens taken into account to compute prob. \n",
    "        distribution of the next token\n",
    "        length (str): maximum sequence length of randomly generated words\n",
    "        estimator (str): ml_estimator or SimpleGoodTuringProbDist\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    ngram = BasicNgram(n, tokens, estimator=estimator)\n",
    "    start_seq = list(ngram.contexts()[0])\n",
    "    # print(start_seq)\n",
    "    sent = []\n",
    "    for i in range(length):\n",
    "        word = ngram[tuple(start_seq)].generate()\n",
    "        start_seq = start_seq[1:] + [word]\n",
    "        # print(start_seq)\n",
    "        sent.append(word)\n",
    "    post_process(sent)\n",
    "\n",
    "\n",
    "def post_process(sent):\n",
    "    \"\"\"Post process randomly generated sequnece of words into readable sentence.\n",
    "\n",
    "    Args:\n",
    "        sent (list): sequence of random words\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    # References: https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "    result = TreebankWordDetokenizer().detokenize(sent)\n",
    "    ## Alternative to TreebankWordDetokenizer\n",
    "    # result = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', sent)\n",
    "    result = '. '.join(\n",
    "        map(lambda s: s.strip().capitalize(), result.split('.')))\n",
    "\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In gibeon. Woe is outrageous; or come up, he was the lord hath he feared not with joy. And smite thee. And saul, we utterly destroyed. He said, thou shalt hearken unto the mountains might live: so it up at midnight, harden the heavens, which thou hast set my father, which stood about them that sojourneth among you, which the midst. Thus ye what things teach his stripes above upon the heathen. Yea, according to hear, and defiled; behold, ye ,\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/kingjamesbible_tokenized.txt\"\n",
    "tokens = data_prep(filename)\n",
    "punct_sent = text_generate(tokens, n=2, length=100, estimator=ml_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the earth bringeth forth, both the corners of your great wickedness, and his mother leah. Then was daniel brought in before the priest, saying, absalom's house, and speak in the strife of tongues. Let them rejoice from their path: and like oil into the chamber of johanan the son of neri, which my lord shall sell unto thee, put ye on one side of it, he said, ye are the children of ammon, and they went out, and came by the lord of hosts\n"
     ]
    }
   ],
   "source": [
    "punct_sent = text_generate(tokens, n=3, length=100, estimator=ml_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the beginning of the creation god made them male and female of all flesh, as god had commanded him concerning this thing. And they laughed him to scorn, and mocked him, and smote them. And joshua the son of ahikam the son of hilkiah, and they took the robe off from him, and brought in peter. Then saith pilate unto him, behold, one like the appearance of the vision. So he measured the length thereof was threescore cubits, even unto the water gate toward the east ;\n"
     ]
    }
   ],
   "source": [
    "punct_sent = text_generate(tokens, n=4, length=100, estimator=ml_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above sentences were generated using `kingjamesbible_tokenized.txt` data.\n",
    "Above, can be seen some randomly generated texts with n ranging from `n=2 to 4`. The random sentence makes more sense with `n=2`. This is because of the fact that the most important information of a word is captured in words appearing before or after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangeet/sagar/anaconda3/lib/python3.8/site-packages/nltk/probability.py:1456: UserWarning: SimpleGoodTuring did not find a proper best fit line for smoothing probabilities of occurrences. The probability estimates are likely to be unreliable.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the houses: for the bodies of clay, of the sword upon all the days of lot for the defence and refuge in times past. And in it, and they cried so much as in the eighth day shall there be wailing: for that ye will surely deliver us out of the lord of hosts the holy ghost: (for thou shalt build bulwarks against the syrians until the time of the lord hath put all these which were without number. Arise, cry. Woe unto that good land. So shall\n"
     ]
    }
   ],
   "source": [
    "punct_sent = text_generate(\n",
    "    tokens, n=3, length=100, estimator=goodturing_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the land; lotan, duke teman, and meshech, and said unto joseph, and saul said to his house. And the whole earth. To many people to labour. This is he then vex himself, and to another, we have sinned. The children of men: and they roasted the passover. For i will set my sanctuary, unto jerusalem; and took selah by war, take thee a sanctuary therein for ever. But esaias is very pure: therefore were come out of the amorites: and\n"
     ]
    }
   ],
   "source": [
    "punct_sent = text_generate(\n",
    "    tokens, n=3, length=100, estimator=goodturing_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some randomly generated text using `estimator=goodturing_estimator` from the same corpora as above. SimpleGoodTuring has however failed to find a proper fit in the probability distribution and thus the randomly generated tokens seem irrelevant to the last `n-1` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma, most happy. He was going by mr. Weston. Weston' s wishing that disdain of the last, mrs. Knightley, \" how you could observe that she must be too large amongst all as when the sound of my mother and no use to lose. Weston, no--beds. -- had she knew better. His dejection was not in the whole party, if you, the circumstances had in one mouth--and was no other night, and in his wife and the hill, quickly, and\n"
     ]
    }
   ],
   "source": [
    "# References: https://www.nltk.org/book/ch02.html\n",
    "emma = gutenberg.words('austen-emma.txt')[1:]\n",
    "punct_sent = text_generate(emma, n=2, length=100, estimator=ml_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma by jane austen 1816] volume i chapter i a very successful visit :-- i thought he would have thrown yourself out of the difficulty of procuring exactly the young man, than to me, when mr. Elton looked up to the utmost exertion necessary on emma' s begging to be danced about in front of the matter. He did not know that _she_ cannot gain by the two circumstances, they found themselves, had certainly been, \" oh! yes, i do not spoil them, the shops, and his\n"
     ]
    }
   ],
   "source": [
    "punct_sent = text_generate(emma, n=3, length=100, estimator=ml_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of randomly generated text using `austen-emma.txt` data using NLTK's corpus Gutenberg. A more meaningful can be read in the randomly generated sentence with `n=2` and `ml_estimator`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
