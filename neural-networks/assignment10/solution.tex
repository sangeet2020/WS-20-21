
\def\pathToRoot{../../}
\input{\pathToRoot/headers/uebungsheader.tex}

\def\issolution{}

\begin{document}

% {Sheet number}{headline}{deadline}
\exercisehead{10}{Sequence Modeling: Recurrent and Recursive Nets}{02.02.2021, 23:59}

\section*{Exercises}

\begin{exercise}[Architecture][0.5 + 1.5 = 2]

\begin{enumerate}
	\item What is the benefit of an LSTM over RNN? Give a short explanation (2-4 sentences).
	\item Draw an LSTM cell and provide the formulas used to calculate each element. Explain
the function of each element.  
\end{enumerate}

\end{exercise}


\begin{solution}
   % write the solution here

\end{solution}

\begin{exercise}[Embeddings] [1 + 0.5 + 0.5 = 2]

    To perform the following exercise you have to read an \href{https://towardsdatascience.com/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598}{article about static and contextualized embeddings.} Answer the following questions based on the article:

    \begin{enumerate}
        \item Give short explanations of static and contextualized word embeddings. Provide examples.
        \item What are the advantages of contextualized (dynamic) word embeddings over static ones?
        \item What is transfer learning? On which task is a model (e.g. BERT) pre-trained? (\textbf{Hint:} read the article till the end) Can we pre-train without any task? Why / why not?
    \end{enumerate}
        
\end{exercise}

\begin{solution}
   % write the solution here
\end{solution}

\begin{exercise}[Exam Preparation][6]

Start preparing for the exam: \\
Go over all the chapters and create the structure of the course.
You can do it in form of a mind map, bullet points structure etc., whatever format works better for you.

\end{exercise}


\begin{solution}
   % write the solution here or attach it in a separate file

\end{solution}

\end{document}
